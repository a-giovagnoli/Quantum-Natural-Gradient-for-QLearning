{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [1. Theory](#chapter1)\n",
    "    * [1.1 Classical natural gradient](#section_1_1)\n",
    "    * [1.2 Quantum natural gradient](#section_1_2)\n",
    "    * [1.3 Code implementation problems](#section_1_3)\n",
    "    * [1.4 Code implementation solutions](#section_1_4)\n",
    "* [2. Code](#chapter2)\n",
    "    * [2.I Parameters](#section_2_I)\n",
    "    * [2.II Imports](#section_2_II)\n",
    "    * [2.1 Replay Memory](#section_2_1)\n",
    "    * [2.2 Quantum Variational Circuit](#section_2_2)\n",
    "    * [2.3 Agent](#section_2_3)\n",
    "    * [2.4 Main](#section_2_4)\n",
    "* [3. Comparison code](#chapter3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Theory <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Classical natural gradient  <a class=\"anchor\" id=\"section_1_1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural netowork (or QVC, in our case), is a function approximator. \n",
    "Training a neural network means finding the parameters that best bring it closer to the unkwnown function that theoretically perfectly solves the task.\n",
    "In doing so, it makes sense to work in the space of distributions. In the In order to measure the distance between two distributions we have to introduce a metric. A common one is the KL divergence. So we define the distance between two distributions as:\n",
    "\n",
    "$$\n",
    "    D_{KL}(f|g) = \\sum\\limits_{x \\in X} f(x) \\log\\left( \\frac{f(x)}{g(x)} \\right)\n",
    "$$\n",
    "\n",
    "where, in the case of neural networks, we can interpret $f$ as the function approximator, $g$ the function we want it to approach, and $X$ out training data.\n",
    "\n",
    "Once we introduce a new metric in a space, this leads to a different notion of distance. \n",
    "In fact we have two different spaces:\n",
    "1) The space where the functions leave, and where the metric is the KL-divergence </br>\n",
    "2) The space where the representation is coordinates of the functions leave, and where the metric is the euclidean one, so the identity matrix.\n",
    "\n",
    "For example, if we consider a gaussian distribution of mean $\\mu$ and standard deviation $\\sigma$, then we can represent a gaussian as the point $(\\mu, \\sigma) \\in \\mathbb{R}^2$. \n",
    "\n",
    "Now let's say we have two gaussians, $\\mathcal{N_1}$ and $\\mathcal{N_2}$, and we represent them as two vectors in $\\mathbb{R}^2$: $\\vec{n}_1 = (\\mu_1, \\sigma_1)$ and $\\vec{n}_2 = (\\mu_2, \\sigma_2)$. Then we can calculate the distance between these two gaussians with the standard euclidean way: \n",
    "\n",
    "$$\n",
    "D_{Euclidean}(\\mathcal{N_1}|\\mathcal{N_2}) = \\|\\vec{n}_1 - \\vec{n}_2\\| = \\sqrt{(\\vec{n}_1 - \\vec{n}_2)\\cdot(\\vec{n}_1 - \\vec{n}_2)} = \\sqrt{(\\mu_1 - \\mu_2)^2 + (\\sigma_1 - \\sigma_2)^2}\n",
    "$$\n",
    "\n",
    "This is basically what we do when we do the standard optimization methods: we consider two functions, the function approximator $f$ depending on the parameters $\\theta_f$ and the theoretical unknown function $g$, depending on the parameters $\\theta_g$, we calculate the gradient in the space of the parameters, and then we update them, so that $f$ gets closer to $g$. Getting closer means thoguh getting closer in the sense of the euclidean metric for the parameters. We are saying that at each training step $\\|\\theta_f - \\theta_g\\|$ gets smaller.\n",
    "\n",
    "Now we remember thoguht that the functions leave not in the euclidean space, where we resemble them with the parameters. They belong instead in a space where we set a different notion of distance. With the example of the two gaussians above, the distance would be:\n",
    "\n",
    "$$\n",
    "    D_{KL}(\\mathcal{N_1}|\\mathcal{N_2}) = \\sum\\limits_{x \\in X} \\mathcal{N_1}(x) \\log\\left( \\frac{\\mathcal{N_1}(x)}{\\mathcal{N_1}(x)} \\right)\n",
    "$$\n",
    "\n",
    "So the question now is: provided that we have a new notion of distance, how should we move in the space of the parameters $(\\mu, \\sigma)$, which is the only thing we can control, so that the $D_{KL}$ gets smaller, and not the $D_{Euclidean}$?\n",
    "\n",
    "From the equations above we can see that the notion of distance depends on the scalar product. We measure the lenghts of a vector as, ignoring the square root:\n",
    "\n",
    "$$\n",
    "    \\|\\vec{v}\\|^2 = \\vec{v} \\cdot \\vec{v} = \\sum\\limits_{i = 1}^N v^2_i = \\sum\\limits_{i = 1}^N v_i \\mathbb{1}_{ij} v_j = \\vec{v}^t \\mathbb{1} \\vec{v}\n",
    "$$\n",
    "\n",
    "where, in the last equation, we introduced explicitly the identity matrix.\n",
    "\n",
    "The point is to understand which matrix we should use to measure the distance with respect to the $D_{KL}$ insted of the euclidean one, so which matrix should take the place of the identity one in the above equation.\n",
    "\n",
    "In can be proved [1] that the matrix that naturally comes up expanding the $D_{KL}$ up to the second order is the Fisher information matrix [2], which has the form:\n",
    "\n",
    "$$\n",
    "    F = \\mathbb{E}_{x}\\left[ \\nabla_{\\theta}f(x) \\nabla_{\\theta}f(x)^t \\right]\n",
    "$$\n",
    "\n",
    "More specifically it can be proved that \n",
    "\n",
    "$$\n",
    "    D_{KL}(f_{\\theta} | f_{\\theta + d}) \\approx \\frac{1}{2}d^t F d\n",
    "$$\n",
    "\n",
    "which resembles the equation above, where now $\\vec{d}$ is the vector inside the scalar product, and we see that the matrix that appears naturally, and that represents the metric tensor, is the fisher information matrix.\n",
    "\n",
    "We now discovered that, if we want to move in the space of parameters in such a way that the $D_{KL}(f|g)$ gets smaller, and not the euclidean one, then we have to measure the distances using the Fisher information matrix. \n",
    "\n",
    "How does it affect the steps we are taking with the gradient? It can be proved [1] that the gradient gets affected in the following way: if we call $\\tilde{\\nabla}_{\\theta}f$ the gradient that takes into account the new notion of distance, then\n",
    "\n",
    "$$\n",
    "    \\tilde{\\nabla}_{\\theta}f = F^{-1}\\nabla_{\\theta}f \n",
    "$$\n",
    "\n",
    "\n",
    "References part 1: </br>\n",
    "[1] https://agustinus.kristia.de/techblog/2018/03/14/natural-gradient/ </br>\n",
    "[2] https://agustinus.kristia.de/techblog/2018/03/11/fisher-information/ </br>\n",
    "[3] https://deep-and-shallow.com/2020/04/01/the-gradient-boosters-via-natural-gradient/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Quantum natural gradient  <a class=\"anchor\" id=\"section_1_2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to understand how to translate the Fisher information matrix in the quantum case. A quantum analogue of the Fisher information matrix, which reduces to the classical one in the classical limit, has been proposed [1]. This is called the Fubini-Study metric, and we call it $g$. There is a good explanation in a pennylane tutorial [2].\n",
    "\n",
    "The Fubini-Study metric is defined as follows: let's consider a quantum circuit made of parametrised gates, which we will call $V(\\theta)$ and unparametrised gates, which we will call $W$. Then the whole circuit $U(\\theta)$ is:\n",
    "\n",
    "$$\n",
    "    U(\\theta)|\\psi_0> = V_{L}(\\theta_{L})W_{L} V_{L-1}(\\theta_{L-1})W_{L-1} \\dots V_{0}(\\theta_{0})W_{0} |\\psi_0>\n",
    "$$\n",
    "\n",
    "for each parametric layer $l$ in the variational quantum circuit the $n_l \\times n_l$ block diagonal submatrix of the Fubini-Study tensor $g^{(l)}_{ij}$ is\n",
    "\n",
    "$$\n",
    "    g^{(l)}_{ij} = <\\psi_{l-1}|K_i K_j|\\psi_{l-1}> - <\\psi_{l-1}|K_i|\\psi_{l-1}><\\psi_{l-1}|K_j|\\psi_{l-1}>\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "    |\\psi_{l-1}> = V_{l-1}(\\theta_{l-1})W_{l-1} \\dots V_{0}(\\theta_{0})W_{0} |\\psi_0>\n",
    "$$\n",
    "\n",
    "\n",
    "References part 2: </br>\n",
    "[1] https://arxiv.org/pdf/1909.02108.pdf </br>\n",
    "[2] https://pennylane.ai/qml/demos/tutorial_quantum_natural_gradient.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Code implementation problems  <a class=\"anchor\" id=\"section_1_3\"></a> \n",
    "\n",
    "We can use the natural gradient in pennylane simply by selecting the Qunatum Natural Gradient optimizer. \n",
    "\n",
    "As an example, let's use the one given by the pennylane tutorial mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit definition\n",
    "dev = qml.device(\"default.qubit\", wires=3)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(params):\n",
    "    # |psi_0>: state preparation\n",
    "    qml.RY(np.pi / 4, wires=0)\n",
    "    qml.RY(np.pi / 3, wires=1)\n",
    "    qml.RY(np.pi / 7, wires=2)\n",
    "\n",
    "    # V0(theta0, theta1): Parametrized layer 0\n",
    "    qml.RZ(params[0], wires=0)\n",
    "    qml.RZ(params[1], wires=1)\n",
    "\n",
    "    # W1: non-parametrized gates\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "\n",
    "    # V_1(theta2, theta3): Parametrized layer 1\n",
    "    qml.RY(params[2], wires=1)\n",
    "    qml.RX(params[3], wires=2)\n",
    "\n",
    "    # W2: non-parametrized gates\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "\n",
    "\n",
    "    return qml.expval(qml.PauliY(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run a circuit with a classical gradient and a quantum natural gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "steps = 200\n",
    "init_params = np.array([0.432, -0.123, 0.543, 0.233], requires_grad=True)\n",
    "\n",
    "\n",
    "# quanntum natural gradient cost and optimizer\n",
    "qng_cost = []\n",
    "opt = qml.QNGOptimizer(0.01)\n",
    "\n",
    "# training loop with quantum natural gradient\n",
    "theta = init_params\n",
    "for _ in range(steps):\n",
    "    theta = opt.step(circuit, theta)\n",
    "    qng_cost.append(circuit(theta))\n",
    "    \n",
    "# classical gradient cost and optimizer\n",
    "gd_cost = []\n",
    "opt = qml.GradientDescentOptimizer(0.01)\n",
    "\n",
    "#training loop with classical gradient\n",
    "theta = init_params\n",
    "for _ in range(steps):\n",
    "    theta = opt.step(circuit, theta)\n",
    "    gd_cost.append(circuit(theta))\n",
    "    \n",
    "\n",
    "# plot results\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.plot(gd_cost, \"b\", label=\"Vanilla gradient descent\")\n",
    "plt.plot(qng_cost, \"g\", label=\"Quantum natural gradient descent\")\n",
    "\n",
    "plt.ylabel(\"Cost function value\")\n",
    "plt.xlabel(\"Optimization steps\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is confusing is the fact that the function `opt.step()` wants, as a first argument, the objective function. Which means that here the circuit itself is passed as an objective function. So the algorithm here is simply trying to minimize the output of the circuit itself. \n",
    "\n",
    "So let's try to set a different cost function, and then run the same code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function = MSE between the output of the circuit and 0\n",
    "def cost(theta):\n",
    "    loss = (circuit(theta))**2\n",
    "    return loss\n",
    "\n",
    "# quanntum natural gradient cost and optimizer\n",
    "qng_cost = []\n",
    "opt = qml.QNGOptimizer(0.01)\n",
    "\n",
    "# training loop with quantum natural gradient\n",
    "theta = init_params\n",
    "for _ in range(steps):\n",
    "    theta = opt.step(cost, theta)\n",
    "    qng_cost.append(circuit(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem seems to be that pennylane can automatically calculate the quantum natural gradient, thus the metric tensor, only if the objective function is a pure quantum node, so if no mathematical manipulation is involved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Code implementation solutions  <a class=\"anchor\" id=\"section_1_4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, looking online, I found the following [1] discussion where they talk about the same problem:\n",
    "\n",
    "Here the pennylane developer says that, altohugh there is not a ready implemented way to calculate the natural gradient automatically, we can derive manually the mathematical part of the cost function, and then, when it comes to deriving the circuit, adding the metric tensor. \n",
    "\n",
    "For example, in our case, the loss function without target net is:\n",
    "\n",
    "$$\n",
    "    L = \\mathbb{E}_{a, s, s'} \\left[ \\left(r + \\gamma \\max Q(s', a;\\theta) - Q(s, a;\\theta)\\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "If we derive it with the natural gradient $\\tilde{\\nabla}_{\\theta}$:\n",
    "\n",
    "$$\n",
    "    \\tilde{\\nabla}_{\\theta}L =  \\tilde{\\nabla}_{\\theta} \\mathbb{E} \\left[ \\left(r + \\gamma \\max Q(s', a;\\theta) - Q(s, a;\\theta)\\right)^2 \\right] = \\mathbb{E} \\left[ \\tilde{\\nabla}_{\\theta}  \\left(r + \\gamma \\max Q' - Q\\right)^2 \\right] = \\dots\n",
    "$$\n",
    "\n",
    "where we used the fact that can be shown [2] that the gradient can be brought inside the integral of the expected value.\n",
    "\n",
    "Also, from now on I will call $Q' := Q(s', a;\\theta)$ and $Q := Q(s, a;\\theta)$. \n",
    "\n",
    "$$ \n",
    "    \\dots = \\mathbb{E} \\left[ 2 \\left(r + \\gamma \\max Q' - Q\\right) \\cdot  \\tilde{\\nabla}_{\\theta} \\left(r + \\gamma \\max Q' - Q\\right) \\right] = \\mathbb{E} \\left[ 2 \\left(r + \\gamma \\max Q' - Q\\right) \\cdot \\left(\\gamma \\tilde{\\nabla}_{\\theta} \\left(\\max Q'\\right) - \\tilde{\\nabla}_{\\theta}Q \\right) \\right] = \\dots\n",
    "$$\n",
    "\n",
    "Let's write (see Appendix for the explanation) now more explicitly the following derivative $\\tilde{\\nabla}_{\\theta} \\left(\\max Q'\\right)$.\n",
    "\n",
    "$$\n",
    "    \\tilde{\\nabla}_{\\theta} \\left(\\max Q'\\right) = g^{-1} \\nabla_{\\theta}\\left(\\max Q'\\right) = g^{-1} \\cdot \\left(J_{\\theta} Q'(\\theta) \\right)^t \\cdot \\nabla_{Q'} max(Q')\n",
    "$$\n",
    "\n",
    "So, inserting this back into the equation:\n",
    "\n",
    "$$\n",
    " \\dots = \\mathbb{E} \\left[ 2 \\left(r + \\gamma \\max Q' - Q\\right) \\cdot \\left(\\gamma \\cdot g^{-1} \\cdot \\left(J_{\\theta} Q'(\\theta) \\right)^t \\cdot \\nabla_{Q'} max(Q')  - \\tilde{\\nabla}_{\\theta}Q \\right) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Now I had to figure out how to calcualte the derivative of the $\\max$ function, which I didn't know. Analitically it seems to be a pretty hard result to be implemented [3]. But then I thought that, when we do reinforcement learning with classical neural networks, we already have this function as the loss function, which pytorch can derive during the backpropagation. So I thought that I only had to try to understand in which way pytorch backpropagates thorough the max function. Apparently [4] pytorch treats the max function as an identity of the max value, thus deriving it giving a 1 on the max value selected, 0 otherwise, so that\n",
    "\n",
    "$$\n",
    "    \\nabla_{Q'} max(Q') = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\text{  if  $Q_1$ is chosen, } \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\text { otherwise }\n",
    "$$\n",
    "\n",
    "In conclusion\n",
    "\n",
    "$$\n",
    "    \\tilde{\\nabla}_{\\theta}L = \\mathbb{E} \\left[ 2 \\left(r + \\gamma \\max Q' - Q\\right) \\cdot \\left(\\gamma \\cdot g^{-1} \\cdot \\left(J_{\\theta} Q'(\\theta) \\right)^t \\cdot \\nabla_{Q'} max(Q')  - g^{-1} \\cdot \\nabla_{\\theta}Q \\right) \\right]\n",
    "$$\n",
    "\n",
    "Comments:\n",
    "- g is not in general a constant matrix, it depends on the state since it's evaluated at each point. That's the reason why we cannot group it from the parenthesis, writing only one $g^{-1} ( \\dots)$. In fact, more explicetly, it would be\n",
    "$$\n",
    "    \\tilde{\\nabla}_{\\theta}L = \\mathbb{E} \\left[ 2 \\left(r + \\gamma \\max Q' - Q\\right) \\cdot \\left(\\gamma \\cdot g^{-1}(s') \\cdot \\left(J_{\\theta} Q'(\\theta) \\right)^t \\cdot \\nabla_{Q'} max(Q')  - g^{-1}(s) \\cdot \\nabla_{\\theta}Q \\right) \\right]\n",
    "$$\n",
    "\n",
    "- We keep in mind that $Q(s, a; \\theta)$ is the function representing our QVC, so the one that in the discussion [1] or in the  above section is represented by $U(\\cdot)$, so basically what we have to do is to calculate $g$ manually, tell pennylane to classically derive the circuit and then put them together. \n",
    "\n",
    "Appendix: \n",
    "\n",
    "We call $\\mathbb{R}^n$ the space of parameters and $\\mathbb{R}^m$ the action space. Then, seeing $Q$ as a function of $\\theta$, we have $Q : \\mathbb{R}^n \\to \\mathbb{R}^m$ and $max: \\mathbb{R}^m \\to \\mathbb{R}$\n",
    "\n",
    "We note that we treat the gradients as column vectors $(nx1)$, while actually they would be line vectors $(1xn)$, but since we want to apply a matrix $A = g^{-1}$ on the left, so $A \\nabla_{\\theta}f$, then we have to consider $\\nabla_{\\theta} f$ as a column vector. Otherwise we should do $\\nabla_{\\theta}f A^{t}$. \n",
    "\n",
    "In fact, treating the gradient as it should, namely a line vector $(1xn)$, we would have($-t = -1$ and $t$)\n",
    "\n",
    "$$\n",
    "\\tilde{\\nabla}_{\\theta} max(Q')  = \\nabla_{\\theta} max(Q') g^{-t} = \\nabla_{Q'}max(Q') \\cdot J_{\\theta}Q \\cdot g^{-t}\n",
    "$$\n",
    "\n",
    "in this way the dimensions match: $ (1 \\times n) = (1 \\times n) \\times (n \\times n) = (1 \\times m) \\times (m \\times n) \\times (n \\times n)$.\n",
    "\n",
    "Alternatively, we can treat the gradient as a column vector. In that case:\n",
    "\n",
    "$$\n",
    "\\tilde{\\nabla}_{\\theta} max(Q')  = g^{-1} \\nabla_{\\theta} max(Q')  = \\cdot g^{-1} \\cdot (J_{\\theta}Q)^t \\cdot  \\nabla_{Q'}max(Q') \n",
    "$$\n",
    "\n",
    "Also like this the dimensions match:$(n \\times 1) = (n \\times n) \\times (n \\times 1) = (n \\times n) \\times (n \\times m) \\times (m \\times 1)$\n",
    "\n",
    "References part 4: </br>\n",
    "[1] https://discuss.pennylane.ai/t/variational-classifiers-and-qngoptimizer/524/2 </br>\n",
    "[2] https://ai.stackexchange.com/questions/14321/how-is-the-gradient-of-the-loss-function-in-dqn-derived </br>\n",
    "[3] https://math.stackexchange.com/questions/1237239/what-is-the-derivative-of-max-and-min-functions </br>\n",
    "[4] https://stackoverflow.com/questions/53539348/what-is-the-backward-process-of-max-operation-in-deep-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.I. Parameters <a class=\"anchor\" id=\"section_2_I\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QBITS = 4\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 64\n",
    "NUM_LEARNING_ITERATIONS = 1\n",
    "SHOW_CIRCUIT = False\n",
    "USING_BIASES = False\n",
    "APPLY_SOFTMAX = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.II. Imports <a class=\"anchor\" id=\"section_2_II\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandro/opt/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n",
      "/Users/alessandro/opt/anaconda3/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# usual\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pennylane import numpy as np_pl\n",
    "\n",
    "# scipy\n",
    "import scipy as sp\n",
    "\n",
    "# pennylane and gym\n",
    "import pennylane as qml\n",
    "import gym\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Replay Memory <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    \"\"\"\n",
    "    Handmade replay memory for the agent\n",
    "    \"\"\"\n",
    "    def __init__(self, max_mem_size, input_dim):\n",
    "        # maximum size of memory\n",
    "        self.mem_size = max_mem_size\n",
    "        \n",
    "        # counter of how much info in the memory\n",
    "        self.mem_counter = 0\n",
    "        \n",
    "        # information to be stored\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dim), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dim), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        push new information into the memory\n",
    "        \"\"\"\n",
    "        # index to eventually overwrite past memory\n",
    "        index = self.mem_counter % self.mem_size\n",
    "        \n",
    "        # push the information\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = next_state\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done\n",
    "        \n",
    "        # increase the counter\n",
    "        self.mem_counter += 1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        get some information from the memory\n",
    "        \"\"\"\n",
    "        # get number of info in memory\n",
    "        max_mem = min(self.mem_counter, self.mem_size)\n",
    "        \n",
    "        # select 'batch_size' randon numbers in the interval [0, max_mem]\n",
    "        sample_indices = np.random.choice(a = max_mem, size = batch_size, replace=False)\n",
    "        \n",
    "        # get an array of evenly spaced ints [0, 1, 2,..., batch_size]\n",
    "        batch_indices = np.arange(batch_size, dtype=np.int32)\n",
    "        \n",
    "        # sample from the memory \n",
    "        state_batch = np_pl.tensor(self.state_memory[sample_indices])\n",
    "        new_state_batch = np_pl.tensor(self.new_state_memory[sample_indices])\n",
    "        reward_batch = np_pl.tensor(self.reward_memory[sample_indices])\n",
    "        terminal_batch = np_pl.tensor(self.terminal_memory[sample_indices])\n",
    "        action_batch = self.action_memory[sample_indices]\n",
    "        \n",
    "        return batch_indices, state_batch, new_state_batch, reward_batch, terminal_batch, action_batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Quantum Variational Circuit <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions used later in the QVC class\n",
    "\n",
    "# rotation operators\n",
    "def rotations(w_layer):\n",
    "    for i, w_wire in enumerate(w_layer):\n",
    "        # 3D rotation\n",
    "        theta_x, theta_y, theta_z = w_wire\n",
    "        qml.Rot(theta_x, theta_y, theta_z, wires=i)\n",
    "        \n",
    "# entangling operators \n",
    "def entangling(n_qubits):\n",
    "    for i in range(n_qubits-1):\n",
    "        qml.CNOT(wires=[i,i+1])\n",
    "        \n",
    "    qml.CNOT(wires=[n_qubits-1, 0])\n",
    "\n",
    "# encoding the observations\n",
    "def encode(state):\n",
    "    for i, s in enumerate(state):\n",
    "        # not very elegant this try/except \n",
    "        try:\n",
    "            qml.RX(np.arctan(s), wires=i)\n",
    "            \n",
    "        except:\n",
    "            s = s._value\n",
    "            qml.RX(np.arctan(s), wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QVC(nn.Module):\n",
    "    \"\"\"\n",
    "    Quantum Variational Circuit with a pytorch interface \n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, num_qubits, lr, action_space):\n",
    "        super().__init__()\n",
    "        \n",
    "        # layers and qubits\n",
    "        self.num_layers = num_layers\n",
    "        self.num_qubits = num_qubits\n",
    "        \n",
    "        # action space dim\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        # pennylane device used to simulate the circuit\n",
    "        self.device = qml.device('default.qubit', wires=num_qubits)\n",
    "        # pennylane quantum node\n",
    "        self.qnode = qml.QNode(self.circuit, self.device)\n",
    "    \n",
    "        # parameters\n",
    "        w = np_pl.random.random(size=(self.num_layers, self.num_qubits, 3), requires_grad=True)\n",
    "        w = w*10 - 5\n",
    "        w = 2*np_pl.arctan(w)                \n",
    "        self.weights = w\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = qml.AdamOptimizer(0.01)\n",
    "        \n",
    "        # optionals\n",
    "        self.using_biases = USING_BIASES \n",
    "        self.apply_softmax = APPLY_SOFTMAX\n",
    "        \n",
    "    def circuit(self, weights, states):\n",
    "        \"\"\"\n",
    "        Create the circuit\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode(states)\n",
    "            \n",
    "        # for every layer\n",
    "        for i in range(self.num_layers):\n",
    "            # CNOTs\n",
    "            entangling(self.num_qubits)\n",
    "            \n",
    "            # ROTs\n",
    "            rotations(weights[i])\n",
    "                \n",
    "        return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))]\n",
    "        \n",
    "        \n",
    "    def forward(self, states_batch):\n",
    "        \"\"\" \n",
    "        Forward function \n",
    "        \"\"\"\n",
    "        # call the circuit for every state in the batch\n",
    "        measurements = np_pl.stack([self.qnode(self.weights, state) for state in states_batch])\n",
    "        \n",
    "        # transofrm from numpy tensor to pennylane numpy tensor \n",
    "        measurements = np_pl.array(measurements, requires_grad=True)\n",
    "        \n",
    "        print(measurements.shape, type(measurements))\n",
    "                \n",
    "        # apply biases\n",
    "        if self.using_biases:\n",
    "            measurements = measurements + self.biases\n",
    "                \n",
    "        return measurements\n",
    "        \n",
    "        \n",
    "    def show(self, state):\n",
    "        \"\"\"\n",
    "        Print circuit architecture\n",
    "        \"\"\"\n",
    "        drawer = qml.draw(self.qnode)\n",
    "        print(drawer(self.weights, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Agent <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"\n",
    "    Agent that will implement the deep Q-Learning algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions, max_mem_size = 100000, eps_end=0.01, eps_dec=5e-4):\n",
    "        # agent params\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # action space\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        \n",
    "        # neural net\n",
    "        self.neural_net = QVC(num_layers=NUM_LAYERS, num_qubits=NUM_QBITS, lr=self.lr, action_space=self.action_space)\n",
    "        \n",
    "        # memory\n",
    "        self.memory = ReplayMemory(max_mem_size, input_dims)\n",
    "            \n",
    "    \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        \"\"\"\n",
    "        Store one transition into the memory\n",
    "        \"\"\"\n",
    "        self.memory.push(state, action, reward, state_, done)\n",
    "        \n",
    "        \n",
    "    def choose_action(self, observation):\n",
    "        \"\"\"\n",
    "        Choose next action\n",
    "        \"\"\"\n",
    "        # if epsilon is low enough \n",
    "        if np.random.random() > self.epsilon:\n",
    "            # then choose with the neural net\n",
    "            state = np_pl.tensor([observation])\n",
    "            actions = self.neural_net.forward(state)\n",
    "            action = np_pl.argmax(actions).item()\n",
    "        else:\n",
    "            # otherwise do a random action\n",
    "            action = np.random.choice(self.action_space)\n",
    "        \n",
    "        return action\n",
    " \n",
    "\n",
    "    def quantum_natural_gradient(self):\n",
    "        \"\"\"\n",
    "        Calculate and return the quantum natural gradient\n",
    "        \"\"\"\n",
    "    \n",
    "        # sample some information from the memory\n",
    "        batch_indices, state_batch, new_state_batch, reward_batch, terminal_batch, action_batch = self.memory.sample(self.batch_size)\n",
    "    \n",
    "        # calculate Q(s,a), the Q value of the initial state\n",
    "        Q_itial_state = self.neural_net.forward(state_batch)[batch_indices, action_batch]\n",
    "        \n",
    "        # calculate Q(s',a), the Q value of the final state\n",
    "        Q_final_state = self.neural_net.forward(new_state_batch)\n",
    "        # if the final state was a terminal one, then there is no expected value for future moves\n",
    "        Q_final_state[terminal_batch] = 0.0\n",
    "        # calculate Y = r + γmax(Q(s',a))\n",
    "        Y = reward_batch + self.gamma * np_pl.max(Q_final_state)\n",
    "        \n",
    "        \n",
    "        # redefine weights and circuit\n",
    "        weights = self.neural_net.weights\n",
    "        circuit = self.neural_net.qnode\n",
    "        # pennylane object that is able to calculate the gradient of a circuit\n",
    "        quantum_grad = qml.grad(circuit) \n",
    "        \n",
    "        \n",
    "        # quantum natural gradient evalued in present state\n",
    "        quantum_nat_grad_present_state = np.empty((BATCH_SIZE, NUM_LAYERS, NUM_QBITS, 3))\n",
    "        quantum_nat_grad_next_state = np.empty((BATCH_SIZE, NUM_LAYERS, NUM_QBITS, 3))\n",
    "        \n",
    "        \n",
    "        # compute gradient of Q evaluated in present state\n",
    "        for i, x in enumerate(state_batch):\n",
    "            x = np.array(x, dtype=np.float64)\n",
    "            \n",
    "            print(x.dtype, x)\n",
    "            print(weights.dtype, weights)\n",
    "            \n",
    "            # compute the classical gradient of each QNode with repsect to `weights`\n",
    "            classical_grad_present_state = quantum_grad(weights, x)\n",
    "        \n",
    "            # compute the metric tensor for the present state\n",
    "            num_params = np.prod(classical_grad_present_state.shape)\n",
    "            g = circuit.metric_tensor([weights, x])\n",
    "            \n",
    "            # invert metric tensor\n",
    "            g_inverse = np.linalg.inv(g) \n",
    "    \n",
    "            # apply g^-1 to the classical gradient\n",
    "            quantum_nat_grad_present_state[i] = np.linalg.solve(g_inverse, classical_grad_present_state.flatten()).reshape(*classical_grad_present_state.shape) \n",
    "            \n",
    "            \n",
    "        # compute gradient of Q evaluated in next state\n",
    "        for i, x in enumerate(new_state_batch):\n",
    "            x = np.array(x, dtype=np.float64)\n",
    "            \n",
    "            # compute the classical gradient of each QNode with repsect to `weights`\n",
    "            classical_grad_next_state = quantum_grad(weights, x)\n",
    "            \n",
    "            # compute the metric tensor for the next state\n",
    "            num_params = np.prod(classical_grad_next_state.shape)\n",
    "            g = circuit.metric_tensor([weights, x])\n",
    "            \n",
    "            # invert metric tensor\n",
    "            g_inverse = np.linalg.inv(g)\n",
    "    \n",
    "            # apply g^-1 to the classical gradient\n",
    "            quantum_nat_grad_next_state[i] = np.linalg.solve(g_inverse, classical_grad_next_state.flatten()).reshape(*classical_grad_next_state.shape)\n",
    "            \n",
    "        \n",
    "        # calculate the gradient\n",
    "        natural_gad = 2*( (Y - Q_itial_state)*(quantum_nat_grad_next_state - quantum_nat_grad_present_state) ).mean()\n",
    "            \n",
    "        return natural_grad\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Learn from past experience\n",
    "        \"\"\"\n",
    "        # if there is not enough information in the memory\n",
    "        if self.memory.mem_counter < self.batch_size:\n",
    "            # it's not yet time to learn\n",
    "            return\n",
    "        \n",
    "        # otherwise, for a certain amount of iterations\n",
    "        for _ in range(NUM_LEARNING_ITERATIONS):\n",
    "            self.neural_net.weights += self.quantum_natural_gradient()\n",
    "            \n",
    "        # decrease epsilon\n",
    "        if self.epsilon > self.eps_min:\n",
    "            self.epsilon = self.epsilon - self.eps_dec\n",
    "        else:\n",
    "            self.epsilon = self.eps_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Main <a class=\"anchor\" id=\"section_2_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 score 17.00 last 10 average score 17 epsilon 1.00\n",
      "(64, 2) <class 'pennylane.numpy.tensor.tensor'>\n",
      "(64, 2) <class 'pennylane.numpy.tensor.tensor'>\n",
      "float64 [-0.15728334 -0.98501927  0.15781839  1.53927314]\n",
      "float64 [[[ 1.95225946 -2.376468   -2.57398311]\n",
      "  [ 1.74578449 -2.56262423  0.19412843]\n",
      "  [-0.73551876  1.79267786 -2.67365615]\n",
      "  [-0.51492617 -2.49155222 -1.3299938 ]]\n",
      "\n",
      " [[ 2.51202024  0.37888621  2.27847373]\n",
      "  [ 1.63568513  2.6887829  -2.48172611]\n",
      "  [-2.59458479 -1.7786416  -2.61569145]\n",
      "  [ 2.57618011  2.22706786 -2.55062069]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-32517fd16340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# learn from experience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# start from new observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-06e216d28874>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# otherwise, for a certain amount of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LEARNING_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_natural_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# decrease epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-06e216d28874>\u001b[0m in \u001b[0;36mquantum_natural_gradient\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# compute the classical gradient of each QNode with repsect to `weights`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mclassical_grad_present_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantum_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# compute the metric tensor for the present state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"Evaluates the gradient function, and saves the function value\n\u001b[1;32m    119\u001b[0m         calculated during the forward pass in :attr:`.forward`.\"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mgrad_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m_grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0;34m\"Grad only applies to real scalar-output functions. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;34m\"Try jacobian, elementwise_grad or holomorphic_grad.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad."
     ]
    }
   ],
   "source": [
    "# crate environment \n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# observation and action space\n",
    "n_actions = env.action_space.n\n",
    "input_dim = env.observation_space.shape[0]\n",
    "\n",
    "# create agent\n",
    "agent = Agent(gamma=0.99, epsilon=1, batch_size=64, n_actions=n_actions, eps_end=0.01, input_dims=[input_dim], lr=0.0001)\n",
    "\n",
    "# params\n",
    "scores, eps_history = [], []\n",
    "n_games = 500\n",
    "\n",
    "# for every episode\n",
    "for i in range(n_games):\n",
    "    # reset everything\n",
    "    score = 0\n",
    "    cost = 0\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    grad_norm_weights_episode = []\n",
    "    grad_norm_biases_episode = []\n",
    "    \n",
    "    # while the agent is still playing\n",
    "    while not done:\n",
    "        \n",
    "        # choose an action\n",
    "        action = agent.choose_action(observation)\n",
    "                \n",
    "        # make a step \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "            \n",
    "        # sum the reward\n",
    "        score += reward\n",
    "                \n",
    "        # store the transition \n",
    "        agent.store_transition(observation, action, reward, new_observation, done)\n",
    "                \n",
    "        # learn from experience\n",
    "        agent.learn()\n",
    "        \n",
    "        # start from new observation\n",
    "        observation = new_observation\n",
    "        \n",
    "    # append the score \n",
    "    scores.append(score)\n",
    "\n",
    "    # append epsilon\n",
    "    eps_history.append(agent.epsilon)\n",
    "    \n",
    "    # avrage the score \n",
    "    avg_score = np.mean(scores[-50:])\n",
    "    \n",
    "    # tensorboard writer\n",
    "    writer.add_scalar(\"Score\", score, i)\n",
    "    writer.add_scalar(\"Epsilon\", agent.epsilon, i)\n",
    "\n",
    "    # print information every x episodes\n",
    "    if i%10 == 0:\n",
    "        print('episode', i, 'score %.2f' % score, 'last 10 average score %2.f' % avg_score, 'epsilon %.2f' %agent.epsilon)\n",
    "        if SHOW_CIRCUIT:\n",
    "            agent.neural_net.show(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparison code <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from the pennylane discussion. I try to first make this work, and then understand the bugs in my code comparing it to mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-4c9f8f69bab5>:9: UserWarning: The init module will be deprecated soon, since templates can now provide a method that returns the shape of parameter tensors.\n",
      "  weights = qml.init.strong_ent_layers_normal(n_wires=n_qubits, n_layers=3)\n",
      "/Users/alessandro/opt/anaconda3/lib/python3.8/site-packages/pennylane/qnode.py:755: UserWarning: The QNode.metric_tensor method has been deprecated. Please use the qml.metric_tensor transform instead.\n",
      "  warnings.warn(\n",
      "/Users/alessandro/opt/anaconda3/lib/python3.8/site-packages/autograd/numpy/numpy_wrapper.py:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return _np.array(args, *array_args, **array_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit evaluation: 0.659917798365038\n",
      "Gradient evaluation: [[[-2.82383286e-02  6.20357635e-02  4.86061353e-05]\n",
      "  [ 4.86080496e-03  2.49220891e-02  1.35578412e-02]\n",
      "  [ 8.27616773e-05  1.76661976e-03  1.52114969e-04]]\n",
      "\n",
      " [[ 1.39460856e-02  1.13923766e-02  2.39830574e-02]\n",
      "  [ 2.41788763e-02 -2.29730655e-02  2.41615789e-02]\n",
      "  [ 2.42046412e-02  1.79156764e-03  2.40034693e-02]]\n",
      "\n",
      " [[ 3.98986399e-17  0.00000000e+00  4.16333634e-17]\n",
      "  [ 2.39549386e-02 -1.92856245e-02  2.77555756e-17]\n",
      "  [ 2.73536356e-04 -7.16508789e-02  2.77555756e-17]]]\n",
      "Cost evaluation: 0.19946544258592827\n",
      "Cost gradient: (array([[[-2.57783756e-02,  4.22319389e-02, -4.21020502e-03],\n",
      "        [ 7.92981994e-03,  1.74379232e-02,  3.28446985e-02],\n",
      "        [ 9.42700672e-07,  6.70674968e-04, -1.25659129e-04]],\n",
      "\n",
      "       [[ 3.07326507e-02,  9.16593276e-03,  3.88823690e-02],\n",
      "        [ 4.64303602e-02, -1.49282051e-02,  4.75777614e-02],\n",
      "        [ 4.84616329e-02,  8.26540554e-03,  4.81394543e-02]],\n",
      "\n",
      "       [[-1.17961196e-16, -1.64798730e-17, -9.71445147e-17],\n",
      "        [ 4.28836397e-02, -7.40120354e-02, -1.11022302e-16],\n",
      "        [-4.05091680e-03, -5.13378448e-02,  8.67361738e-18]]]), tensor(0.87390725, requires_grad=True))\n",
      "float64 [0.84416752 0.19023803 0.04915377]\n",
      "float64 [[[-0.11961802  0.03891758  0.15919719]\n",
      "  [ 0.00449928  0.12297244  0.17459336]\n",
      "  [ 0.03231587 -0.02690782  0.34416137]]\n",
      "\n",
      " [[-0.03163068  0.07934756  0.10663072]\n",
      "  [-0.06641522  0.03775712 -0.03656947]\n",
      "  [ 0.22377172  0.01339612  0.04131439]]\n",
      "\n",
      " [[-0.02966086  0.06354072 -0.20910046]\n",
      "  [-0.01625204 -0.1771798   0.21194056]\n",
      "  [ 0.00632574  0.10875833  0.09067309]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,3,3) into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4c9f8f69bab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mcost_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cost gradient:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cost natural gradient:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_ng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-4c9f8f69bab5>\u001b[0m in \u001b[0;36mcost_ng\u001b[0;34m(theta, X, expectations)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# compute the metric tensor of each QNode with respect to `weights`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# compute g^{-1} \\nabla U, and reshape it so it has the same shape as `weights`/`qgrad`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mmetric_tensor\u001b[0;34m(self, allow_nonunitary, approx, diag_approx, only_construct, *args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nonunitary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag_approx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nonunitary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag_approx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     def draw(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/transforms/metric_tensor.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhybrid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/transforms/batch_transform.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mshots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shots\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# as trainable. This should be removed at some point, forcing users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# to specify `requires_grad=True` for trainable parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             args = [\n\u001b[0m\u001b[1;32m    575\u001b[0m                 \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"requires_grad\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# to specify `requires_grad=True` for trainable parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             args = [\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"requires_grad\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             ]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# evaluate the original object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/numpy/numpy_wrapper.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(A, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marray_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_from_scalar_or_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/numpy/numpy_wrapper.py\u001b[0m in \u001b[0;36marray_from_args\u001b[0;34m(array_args, array_kwargs, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0marray_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marray_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marray_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoicelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,3,3) into shape (3)"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "from pennylane import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "n_qubits = 3\n",
    "batch_size = 2\n",
    "\n",
    "weights = qml.init.strong_ent_layers_normal(n_wires=n_qubits, n_layers=3)\n",
    "bias = 0.5\n",
    "\n",
    "theta = (weights, bias)\n",
    "X = np.random.random(size=[batch_size, n_qubits])\n",
    "Y = np.random.random(size=[batch_size])\n",
    "\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev.operations.remove(\"Rot\")\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    \"\"\"Variational quantum circuit\"\"\"\n",
    "    AngleEmbedding(x, wires=range(n_qubits))\n",
    "    StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "quantum_grad = qml.grad(circuit, argnum=0)\n",
    "print(\"Circuit evaluation:\", circuit(weights, X[0]))\n",
    "print(\"Gradient evaluation:\", quantum_grad(weights, X[0]))\n",
    "\n",
    "\n",
    "def variational_classifier(theta, x):\n",
    "    \"\"\"Variational quantum classifier\"\"\"\n",
    "    weights = theta[0]\n",
    "    bias = theta[1]\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "\n",
    "def cost(theta, X, expectations):\n",
    "    \"\"\"Cost function for the variational quantum classifier\"\"\"\n",
    "    e_predicted = np.array([variational_classifier(theta, x) for x in X])\n",
    "    loss = np.mean((e_predicted - expectations) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"Cost evaluation:\", cost(theta, X, Y))\n",
    "\n",
    "\n",
    "def cost_ng(theta, X, expectations):\n",
    "    \"\"\"Natural gradient of the cost function\"\"\"\n",
    "    weights = theta[0]\n",
    "    bias = theta[1]\n",
    "\n",
    "    qnatgrad = np.empty((batch_size,) + weights.shape)\n",
    "    e_predicted = np.empty([batch_size])\n",
    "\n",
    "    for idx, x in enumerate(X):\n",
    "        e_predicted[idx] = variational_classifier(theta, x)\n",
    "        \n",
    "        print(x.dtype, x)\n",
    "        print(weights.dtype, weights)\n",
    "\n",
    "        # compute the gradient of each QNode with repsect to `weights`\n",
    "        qgrad = quantum_grad(weights, x)\n",
    "\n",
    "        # compute the metric tensor of each QNode with respect to `weights`\n",
    "        num_params = np.prod(qgrad.shape)\n",
    "        g = circuit.metric_tensor([weights, x])[:num_params, :num_params]\n",
    "\n",
    "        # compute g^{-1} \\nabla U, and reshape it so it has the same shape as `weights`/`qgrad`\n",
    "        qnatgrad[idx] = np.linalg.solve(g, qgrad.flatten()).reshape(*qgrad.shape)\n",
    "\n",
    "    # Take the tensordot between the natural gradient and the loss,\n",
    "    # and divide by the batch size (i.e., taking the mean).\n",
    "    loss_ng = np.tensordot(2 * (e_predicted - expectations), qnatgrad, axes=1) / batch_size\n",
    "    return loss_ng\n",
    "\n",
    "\n",
    "cost_grad = qml.grad(cost, argnum=0)\n",
    "print(\"Cost gradient:\", cost_grad(theta, X, Y))\n",
    "print(\"Cost natural gradient:\", cost_ng(theta, X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 1)\n",
    "print(x)\n",
    "x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
